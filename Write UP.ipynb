{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Traffic Sign Recognition**\n",
    "\n",
    "The goal of the project is to develop a convolutional neural net that recognizes German traffic signs.\n",
    "\n",
    "---\n",
    "\n",
    "**Build a Traffic Sign Recognition Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Load the data set (see below for links to the project data set)\n",
    "* Explore, summarize and visualize the data set\n",
    "* Design, train and test a model architecture\n",
    "* Use the model to make predictions on new images\n",
    "* Analyze the softmax probabilities of the new images\n",
    "* Summarize the results with a written report\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./examples/hist1.PNG \"Histogram\"\n",
    "[image2]: ./examples/9signs.PNG \"Nine Traffic Signs\"\n",
    "[image3]: ./examples/wrongclass.PNG \"Wrongly Classified\"\n",
    "[image4]: ./examples/ownsigns.png \"Own Signs\"\n",
    "[image5]: ./examples/softmax2.png \"Softmax\"\n",
    "[image6]: ./examples/conv1.png \"Conv1\"\n",
    "[image7]: ./examples/conv2.png \"Conv 2\"\n",
    "\n",
    "# Rubric Points\n",
    "In the following, I will consider the [rubric points](https://review.udacity.com/#!/rubrics/481/view) individually and describe how I addressed each point in my implementation.  \n",
    "\n",
    "## Ipython Notebook\n",
    "\n",
    "Here is a link to my [project code](https://github.com/MichaelHopf/CarND-Traffic-Sign-Classifier-Project/blob/master/Traffic_Sign_Classifier.ipynb)\n",
    "\n",
    "\n",
    "## Data Set Exploration\n",
    "\n",
    "### Dataset summary\n",
    "\n",
    "Basic analysis:\n",
    "* Training set size: 34799\n",
    "* Validation set size: 4410\n",
    "* Test set size: 12630\n",
    "* Number of classes: 43\n",
    "* Image data shape: (32,32,3)\n",
    "\n",
    "\n",
    "### Dataset visualization\n",
    "\n",
    "The dataset consists of 43 different German traffic signs. However, some signs appear much more often in the training set (or validation set) than others. This can be seen in the following histogram. I did not check the distribution of the signs of the test set to avoid introducing a bias.\n",
    "\n",
    "![image1]\n",
    "\n",
    "\n",
    "When viewing some of the training images, one could see that, even for a human, some are quite difficult to recognize, especially due to the low brithness. Here are nine sample images:\n",
    "\n",
    "![alt text][image2]\n",
    "\n",
    "\n",
    "## Design and Test a Model Architecture\n",
    "\n",
    "### Preprocessing\n",
    "I normalized the images as follows: For each color channel, I calculated the mean over the training set and subtracted it. Then, I divided by 128. I did not do any data augmentation.\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "I started building my net from the basic architecture of LeNet. However, since I did not grayscale the input, I wanted to net to extract important color features itself. Therefore, I used a 1x1 convolution at the beginning with a depth of 10. Then, basically the LeNet architecture follows. However, I substituted the first 5x5 convolution with two 3x3 convolutions of a little greater depth. Also, I introduced three dropout layers in total.\n",
    "\n",
    "My final model consisted of the following layers:\n",
    "\n",
    "| Layer         \t\t|     Description\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| Input         \t\t| 32x32x3 RGB image   \t\t\t\t\t\t\t| \n",
    "| Convolution 1x1     \t| 1x1 stride, valid padding, outputs 32x32x10 \t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Convolution 3x3     \t| 1x1 stride, valid padding, outputs 30x30x10 \t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Convolution 3x3     \t| 1x1 stride, valid padding, outputs 28x28x12 \t|\n",
    "| Dropout\t\t\t\t| 0.5\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Max pooling\t      \t| 2x2 stride,  outputs 14x14x12 \t\t\t\t|\n",
    "| Convolution 5x5     \t| 1x1 stride, valid padding, outputs 10x10x16 \t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Max pooling\t      \t| 2x2 stride,  outputs 5x5x16  \t\t\t\t    |\n",
    "| Flatten    \t\t    | outputs 1x400      \t\t\t\t\t\t\t|\n",
    "| Fully connected\t\t| outputs 1x120     \t\t\t\t\t\t\t|\n",
    "| Dropout\t\t\t\t| 0.5\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Fully connected\t\t| outputs 1x84     \t\t\t\t\t\t\t    |\n",
    "| Dropout\t\t\t\t| 0.5\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Fully connected\t\t| outputs 1x43     \t\t\t\t\t\t\t    |\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Softmax\t\t\t\t| probabilities       \t\t\t\t\t\t\t|\n",
    " \n",
    " \n",
    "\n",
    "### Model Training\n",
    "\n",
    "For training, I used the following hyperparameters:\n",
    "* Learning rate: $5^{-4}$\n",
    "* Number of epochs: $35$\n",
    "* Batch size: $128$\n",
    "* L2 - Regularization: $0$ (no L2 regularization was used)\n",
    "* Dropout Parameter: $0.5$\n",
    "* Optimizer: Adam\n",
    "* Training time: $\\approx$ 2 hours (using Microsoft Surface)\n",
    "\n",
    "In particular, it is worth mentioning that the three dropout layers did a sufficient job of regularizing. Thus, I observed that additional L2 regularization was not beneficial.\n",
    "\n",
    "\n",
    "### Solution Approach\n",
    "\n",
    "As already mentioned, I started with the well-known LeNet architecture and added a few more layers. In particular, the three Dropout layers are helpful to prevent overfitting. I added a 1x1 convolution at the beginning to let the net learn what color features are important. Also, I substituted the first 5x5 Convolution of LeNet with two 3x3 Convolutions to make the net a little bit deeper.\n",
    "\n",
    "After training for 35 epochs, I ended up with the following accuracies:\n",
    "* Training set accuracy: $99.3\\%$\n",
    "* Validation set accuracy: $96.2\\%$\n",
    "* Test set accuracy: $94.85\\%$\n",
    "\n",
    "This still indicates that the model is overfitting the data. A more extensive hyperparameter search or data augmentation maybe could better the results with the same net. Since I used a Microsoft Surface for training, I could not do an extensive hyperparameter search.\n",
    "\n",
    "In the following picture, we can see 20 (out of 651) wrongly classified traffic sign from the test set:\n",
    "\n",
    "![alt text][image3]\n",
    "\n",
    "One can notice that even if the prediction is wrong, the predicted sign is often similiar, e.g., speed limit signs are often recognized as speed limit signs but with a different speed, or the 'traffic signals' sign is confused with the 'general caution' sign.\n",
    "\n",
    "\n",
    "## Test a Model on New Images\n",
    "\n",
    "\n",
    "### Acquiring New Images\n",
    "\n",
    "Since I live in Germany, I took 35 photos of traffic signs. Some of seem to be quite easily recognizable while others are hard to identify even for a human. Also, I noticed that some traffic signs occur much more frequently than others.\n",
    "\n",
    "\n",
    "### Performance on New Images\n",
    "\n",
    "The net did not perform well on my own images with an accuracy of approximately $82\\%$. The following picture shows which signs were wrongly classified.\n",
    "\n",
    "![alt text][image4]\n",
    "\n",
    "\n",
    "### Model Certainty - Softmax Probabilities\n",
    "\n",
    "In the following picutre, we can see the softmax probabilities of the last seven traffic signs of my own dataset.\n",
    "\n",
    "![alt text][image5]\n",
    "\n",
    "\n",
    "\n",
    "### (Optional) Visualizing the Neural Network (See Step 4 of the Ipython notebook for more details)\n",
    "\n",
    "\n",
    "The next picture shows the feature maps of the first 1x1 convolution. We can observe that some neurons react to brigth and some to dark parts.\n",
    "\n",
    "![alt text][image6]\n",
    "\n",
    "\n",
    "The next picture shows the feature maps of the first 3x3 convolution. We can observe that shapes become now more important (see also Ipython notebook for further details.\n",
    "\n",
    "![alt text][image7]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
